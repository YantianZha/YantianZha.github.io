---
layout: page
title:
permalink: /

pubs:

    - title:   "<font color='#02D8E8' style='font-size:1.3em;'><strong>AAM-SEALS</strong></font>: Developing <font color='#02D8E8' style='font-size:1.3em;'><strong>A</strong></font>erial-<font color='#02D8E8' style='font-size:1.3em;'><strong>A</strong></font>quatic <font color='#02D8E8' style='font-size:1.3em;'><strong>M</strong></font>anipulators in <font color='#02D8E8' style='font-size:1.3em;'><strong>SE</strong></font>a, <font color='#02D8E8' style='font-size:1.3em;'><strong>A</strong></font>ir, and <font color='#02D8E8' style='font-size:1.3em;'><strong>L</strong></font>and <font color='#02D8E8' style='font-size:1.3em;'><strong>S</strong></font>imulator"
      author:  "William Yang, Karthikeya Kona, Yashveer Jain, Abhinav Bhamidipati, Tomer Atzili, Xiaomin Lin, Yantian Zha"
      journal: "arXiv, 2024; ICRA Amphibious Robotics Workshop, 2025"
      url: "https://arxiv.org/pdf/2412.19744"
      media:
        - name: "Website"
          url:  "https://aam-seals.umd.edu/"
        - name: "Poster"          
          url: "https://drive.google.com/file/d/1wyj_gF96U6ELItr4Ddl8YfpxQvU9X6Ps/view?usp=sharing"
               
    - title:   "NatSGLD: A Dataset with <ins>S</ins>peech, <ins>G</ins>estures, <ins>L</ins>ogic, and <ins>D</ins>emonstrations for Robot Learning in <ins>Nat</ins>ural Human-Robot Interaction"
      author:  "Snehesh Shrestha, Yantian Zha, Saketh Banagiri, Ge Gao, Yiannis Aloimonos, Cornelia Fermüller"
      journal: "IEEE/ACM International Conference on Human-Robot Interaction (Data Paper), 2025"
      url: "https://arxiv.org/pdf/2502.16718"
      media:
        - name: "Website"
          url:  "http://www.snehesh.com/natsgld/"
   
    - title:   "Task Success is not Enough: Investigating the Use of VideoLanguage Models as Behavior Critics for Catching Undesirable Agent Behaviors"
      author:  "Lin Guan, Yifan Zhou, Denis Liu, Yantian Zha, Heni Ben Amor, Subbarao Kambhampati"
      journal: "Conference on Language Modeling 2024"
      url: "https://openreview.net/forum?id=otKo4zFKmH#discussion"
      media:
        - name: "Website"
          url:  "https://guansuns.github.io/pages/vlm-critic/"
  
    - title:   "Learning from Ambiguous Demonstrations with Self-Explanation Guided Reinforcement Learning"
      author:  "Yantian Zha, Lin Guan, Subbarao Kambhampati"
      journal: "AAA-24 Main Track & AAAI-22 Workshop on Reinforcement Learning in Games 2022."
      url:     "https://arxiv.org/pdf/2110.05286.pdf"
      media:
        - name: "Website"
          url:  "https://github.com/YantianZha/SERLfD"
        - name: "Slides"
          url: "https://yantianzha.github.io/serlfd_slides/"
      
    - title:   "Symbols as a Lingua Franca for Bridging Human-AI Chasm for Explainable and Advisable AI Systems"
      author:  "Subbarao Kambhampati, Sarath Sreedharan, Mudit Verma, Yantian Zha, Lin Guan"
      journal: "AAAI Blue Sky Paper (Senior Member Presentation Track) 2022."
      url:     "https://arxiv.org/pdf/2109.09904.pdf"
      
    - title:   "Contrastively Learning Visual Attention as Affordance Cues from Demonstrations for Robotic Grasping"
      author:  "Yantian Zha, Siddhant Bhambri, and Lin Guan"
      journal: "The IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2021."
      url:     "https://arxiv.org/abs/2104.00878"
      media:
        - name: "Project"
          url: https://sites.google.com/asu.edu/affordance-aware-imitation/project
        - name: "IROS_Talk"
          url: "https://www.youtube.com/watch?v=K71EAN5tNaI"
        - name: "Slides"
          url: https://yantianzha.github.io/AAIL_Slides/

    - title:   "Plan-Recognition-Driven Attention Modeling for Visual Recognition"
      author:  "Yantian Zha, Yikang Li, Tianshu Yu, Subbarao Kambhampati and Baoxin Li"
      journal: "AAAI 2019 Workshop on Plan, Activity, and Intent Recognition (PAIR)."
      url:     "https://arxiv.org/abs/1812.00301"

    - title:   "Recognizing plans by learning embeddings from observed action distributions"
      author:  "Yantian Zha, Yikang Li, Sriram Gopalakrishnan, Baoxin Li, and Subbarao Kambhampati"
      journal: "In Proceedings of International Conference on Autonomous Agents and Multiagent Systems (AAMAS) 2018."
      url:     "https://dl.acm.org/citation.cfm?id=3238103"
      media:
        - name: "Full Paper"
          url: https://arxiv.org/abs/1712.01949
        - name: "Code"
          url: "https://github.com/YantianZha/Distr2Vec"
        - name: "Slides"
          url: https://drive.google.com/open?id=19dSk2Qk2vEqwJXBzbN1XoQJIa-YdMGdY
        - name: "Poster"
          url: https://drive.google.com/open?id=1suKUc865_NNMMnSSXEqJIA7gmjAKlOb2

  
    - title:   "Discovering Underlying Plans Based on Shallow Models"
      author:  "Hankz Hankui Zhuo, Yantian Zha, Subbarao Kambhampati, and Xin Tian"
      journal: "In Proceedings of ACM Transactions on Intelligent Systems and Technology (ACM-TIST) 2019."
      url:     "https://yochan-lab.github.io/papers/files/papers/hankz_tist_19.pdf"
      media:
        - name: "Code"
          url: "https://github.com/YantianZha/Discovering-Underlying-Plans-Based-on-Shallow-Models"

    - title:   "Explicability as Minimizing Distance from Expected Behavior"
      author:  "Anagha Kulkarni, Yantian Zha, Tathagata Chakraborti, Satya Gautam Vadlamudi, Yu Zhang and Subbarao Kambhampati"
      journal: "In Proceedings of International Conference on Autonomous Agents and Multiagent Systems (AAMAS) 2019."
      url:     "https://yochan-lab.github.io/papers/files/papers/anagha-aamas-2019.pdf"
      media:
        - name: "Full Paper"
          url: https://arxiv.org/abs/1611.05497
        - name: "Demo Video"
          url:  "https://youtu.be/iLG-ANQtYms"

---

{% include image.html url="images/photo.png" caption="" max_width="3px" align="right" %}

Yantian was born in [Nanjing](https://en.wikipedia.org/wiki/Nanjing), China. While Yantian started learning piano at three years old (and eventually obtained his [10-Level Piano Certificate](https://drive.google.com/file/d/0BzFSKJBTOGjKRExJZENGajlCVG8/view?usp=sharing&resourcekey=0-KWtW85aPuDjuFek7g6yO7w){:target="_blank"}), Yantian is committed to Robotics (which is one of Yantian's childhood dreams). Yantian's robotics journey truly set out when he was an undergrad, worked with [Prof. Xudong Ma](https://automation.seu.edu.cn/2019/0528/c24505a275234/page.htm){:target="_blank"} and [Prof. Kun Qian](https://automation.seu.edu.cn/2019/0528/c24504a275190/page.htm){:target="_blank"} at the Institute of Intelligent Robotics and Intelligent Control, Southeast University. After that, Yantian went to Arizona State University and had a delighted Ph.D. life with his advisor [Prof. Subbarao Kambhampati (Rao)](http://rakaposhi.eas.asu.edu/){:target="_blank"} (as clearly seen from the title of Yantian's [Ph.D. Thesis](https://yantianzha.github.io/yantianthesis.github.io/){:target="_blank"}). Following this, Yantian became a Postdoctoral Associate and Adjunct Lecturer, collaborating with [Prof. Miao Yu](https://enme.umd.edu/clark/faculty/607/Miao-Yu){:target="_blank"}, [Prof. Bala Balachandran](https://enme.umd.edu/clark/faculty/508/Balakumar-Balachandran){:target="_blank"}, [Prof. Yiannis Aloimonos](http://users.umiacs.umd.edu/~yiannis/){:target="_blank"}, [Dr. Cornelia Fermüller](https://isr.umd.edu/clark/faculty/1168/Cornelia-Ferm%C3%BCller){:target="_blank"}, [Prof. Ming Lin](https://www.cs.umd.edu/people/lin){:target="_blank"}, and [Prof. Tianyi Zhou](https://tianyizhou.github.io/){:target="_blank"} at the University of Maryland, College Park. Currently, Yantian is an Assistant Professor in the Department of Computer Science at North Carolina A&T State University, where he directs the [***Omnidomain AI and Robotics Laboratory*** (**OARL**)](https://yantianzha.github.io/oarl.github.io/){:target="_blank"}.

<span style="color: red;">*I am seeking self-motivated Ph.D. students with strong interests and backgrounds in aerial, underwater, and ground robotics; physics-based simulation; reinforcement learning; machine learning; control theory; and quantum neural networks.*</span>

Research Interest:

Yantian is interested in advancing next-generation robotics and AI to address the dynamic challenges of [**`Society 5.0`**](https://library.oapen.org/bitstream/handle/20.500.12657/41719/2020_Book_Society50.pdf?sequence=1#page=18), a vision of a technology-driven, human-centered future. By integrating **`morphological complexity`**, **`expanded operational workspaces`**, and **`advanced intelligence`**, Yantian develops robotic systems capable of seamless operation across diverse and dynamic environments.

Yantian's research spans **`Cognitive Robotics`**, **`Artificial Intelligence`**, **`Machine Learning`**, **`Human-Robot Collaboration`**, **`Dynamics`**, **`Control`**, **`Cross-Medium Manipulation`**, and **`Advanced Simulators`**, driving innovation at the intersection of technology and societal needs.

Teaching:

[2023 Spring: ENPM808Z Cognitive Robotics](https://docs.google.com/document/d/1RfCNIVXaBYseH8Emi6-MqRROzQ9chSlO1hnIwO-QP4s/edit?usp=sharing){:target="_blank"}

[2023 Fall: CMSC421 Introduction to Artificial Intelligence](https://docs.google.com/document/d/16qWFxya8yX7eqli0KFXa5lACFgTqGPfBPaSzh9uzTh4/edit?usp=sharing){:target="_blank"}

[2024 Spring: CMSC848J & ENPM808Z Cognitive Robotics]()

Please feel free to contact Yantian via [yzha at ncat dot edu](mailto:yzha@ncat.edu) or [LinkedIn](https://www.linkedin.com/in/ytzha){:target="_blank"}. For students who contact me and look for my supervision, I promise to read your emails. I would appreciate it if you could mention which of my papers or research directions you are interested in; please also feel free to suggest any other research directions that you would like us to explore together.

<span style="color:red">News!</span>

05/16/2025: Delivered a keynote talk at the NSF Data Science Symposium, hosted by North Carolina A&T State University.
Talk Title: *Embodied and Human-Aligned Intelligence across Air, Water, and Land: From Simulation to Data-Efficient Learning*

02/07/2025: My student, <span style="color:red">[William Yang](https://www.linkedin.com/in/william-yang-66ab84221){:target="_blank"}</span>, and I were interviewed by the University of Maryland about our <span style="color:red">[Aerial-Aquatic Manipulators](https://arxiv.org/pdf/2412.19744){:target="_blank"}</span> project. Stay tuned for the upcoming news!

12/02/2024: Our paper <span style="color:red">["NatSGLD: A Dataset with <ins>S</ins>peech, <ins>G</ins>estures, <ins>L</ins>ogic, and <ins>D</ins>emonstrations for Robot Learning in <ins>Nat</ins>ural Human-Robot Interaction](http://www.snehesh.com/natsgld/){:target="_blank"}</span> is accepted by HRI-25. Thanks to my collaborators!

08/22/24: I gave a faculty talk at the [Maryland Research Day event](https://www.cs.umd.edu/community/research-day)

07/10/2024: Our paper <span style="color:red">["Task Success" is not Enough: Investigating the Use of Video-Language Models as Behavior Critics for Catching Undesirable Agent Behaviors](https://openreview.net/forum?id=otKo4zFKmH#discussion){:target="_blank"}</span> is accepted by COLM-24. Thanks to my collaborators!

07/03/2024: I gave an invited talk at the Robotics Institute at Carnegie Mellon University: "Cognitively-Enhanced Robotic Manipulation across Sea, Air, and Land"

05/23/2024: I gave a faculty talk at [Maryland Robotics Center Research Symposium 2024](https://robotics.umd.edu/symposium2024)

12/09/2023: Our paper <span style="color:red">[Learning from Ambiguous Demonstrations with Self-Explanation Guided Reinforcement Learning](https://drive.google.com/file/d/1WdI10Rg3jWXfKpos8nqHh7qjJmU0ALOi/view){:target="_blank"}</span> is accepted by AAAI-24 Main Track. Thanks to my collaborators!

07/2023: Excited to announce our workshop [Bridging the Gap between Cognitive Science and Robot Learning in the Real World: Progresses and New Directions](https://yantianzha.github.io/crl.github.io/) at [CoRL-23](https://www.corl2023.org/). Many thanks to my co-organizers!

04/2022: I am a recipient of the [Maryland Robotics Center Postdoctoral Fellowship](https://robotics.umd.edu/education/postdoctoral-fellowship-program-0) at the Institute for Systems Research (ISR), University of Maryland, 2022-2023.

06/30/2021: Our paper <span style="color:red">[Contrastively Learning Visual Attention as Affordance Cues from Demonstrations for Robotic Grasping](https://arxiv.org/abs/2104.00878){:target="_blank"}</span> is accepted by IROS 2021. Thanks to my collaborators!

04/30/2021: I am awarded the CIDSE Doctoral Fellowship by ASU.  

03/2020 - 08/2020: Worked as a robotics research intern at ABB, Raleigh advised by Dr. Jianjun Wang.

# <a name="publications"></a>Publications 

{% for pub in page.pubs %}
[**{{pub.title}}**]({% if pub.internal %}{{pub.url | prepend: site.baseurl}}{% else %}{{pub.url}}{% endif %}){:target="_blank"}<br />
{{pub.author}}<br />
*{{pub.journal}}*
{% if pub.media %}<br />Media: {% for article in pub.media %}[[{{article.name}}]({{article.url}}){:target="_blank"}] {% endfor %}{% endif %}

{% endfor %}
